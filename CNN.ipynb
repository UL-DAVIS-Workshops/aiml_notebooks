{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What parts make up a Convolutional Neural Network\n",
    "\n",
    "- Input layer (i.e. 2D or 3D matrix - image)\n",
    "     - Martix flattened into a 1D vertex\n",
    "- Hidden layers (Artificial Neurons, activation functions, min/max pooling, convolution layers) \n",
    "- Output layer\n",
    "\n",
    "![alt text](figures/Screen-Shot-2017-07-26-at-1.44.58-PM.png \"CNN\")\n",
    "\n",
    "## Convolution layers\n",
    "https://www.jeremyjordan.me/convolutional-neural-networks/\n",
    "\n",
    "A convolution layer defines a window by which we examine a subset of the image, and subsequently scans the entire image looking through this window. As you'll see below, we can parameterize the window to look for specific features (e.g. edges) within an image. This window is also sometimes called a filter, since it produces an output image which focuses solely on the regions of the image which exhibited the feature it was searching for. The output of a convolution is referred to as a feature map.\n",
    "\n",
    "Note: Windows, filters, and kernels all refer to the same thing with respect to convolutional neural networks; don't get confused if you see one term being used instead of another.\n",
    "\n",
    "## Convolution Visualization\n",
    "https://ezyang.github.io/convolution-visualizer/index.html\n",
    "\n",
    "[A guide to convolution arithmetic for deep learning](https://arxiv.org/pdf/1603.07285.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"https://ezyang.github.io/convolution-visualizer/index.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f37c8073d90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(src='https://ezyang.github.io/convolution-visualizer/index.html', width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How are Models Created?\n",
    "!!! TODO: Add description of data set selection. The hidden layers need to be selected to detect features with kernels, activation functions, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.activations import tanh, relu, elu\n",
    "from keras.preprocessing.image import array_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 18s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# This will download the cifar dataset and save to ~/.keras/datasets\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape  # 50,000 32x32 pixel RGB training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F3761BCD590>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_to_img(x_train[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[170, 180, 198],\n",
       "        [168, 178, 196],\n",
       "        [177, 185, 203],\n",
       "        ...,\n",
       "        [162, 179, 215],\n",
       "        [158, 178, 214],\n",
       "        [157, 177, 212]],\n",
       "\n",
       "       [[168, 181, 198],\n",
       "        [172, 185, 201],\n",
       "        [171, 183, 200],\n",
       "        ...,\n",
       "        [159, 177, 212],\n",
       "        [156, 176, 211],\n",
       "        [154, 174, 209]],\n",
       "\n",
       "       [[154, 170, 186],\n",
       "        [149, 165, 181],\n",
       "        [129, 144, 162],\n",
       "        ...,\n",
       "        [161, 178, 214],\n",
       "        [157, 177, 212],\n",
       "        [154, 174, 209]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 74,  84,  80],\n",
       "        [ 76,  85,  81],\n",
       "        [ 78,  85,  82],\n",
       "        ...,\n",
       "        [ 71,  75,  78],\n",
       "        [ 68,  72,  75],\n",
       "        [ 61,  65,  68]],\n",
       "\n",
       "       [[ 68,  76,  77],\n",
       "        [ 69,  77,  78],\n",
       "        [ 72,  79,  78],\n",
       "        ...,\n",
       "        [ 76,  80,  83],\n",
       "        [ 71,  75,  78],\n",
       "        [ 71,  75,  78]],\n",
       "\n",
       "       [[ 67,  75,  78],\n",
       "        [ 68,  76,  79],\n",
       "        [ 69,  75,  76],\n",
       "        ...,\n",
       "        [ 75,  79,  82],\n",
       "        [ 71,  75,  78],\n",
       "        [ 73,  77,  80]]], dtype=uint8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
